<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.4"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>summarize_with_llama_cpp: include/model.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">summarize_with_llama_cpp
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.4 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('model_8h_source.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle"><div class="title">model.h</div></div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="comment">///////////////////////////////////////////////////////////////////////////////</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="comment">// File: model.h</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="comment">//</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="comment">// License: MIT</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="comment">//</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="comment">// Copyright (C) 2025 Onur Ozuduru</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="comment">//</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="comment">// Follow Me!</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="comment">//   github: github.com/onurozuduru</span></div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="comment">///////////////////////////////////////////////////////////////////////////////</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span> </div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="preprocessor">#</span><span class="preprocessor">include</span> <span class="preprocessor">&quot;llama-cpp.h&quot;</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="preprocessor">#</span><span class="preprocessor">include</span> <span class="preprocessor">&lt;</span><span class="preprocessor">ostream</span><span class="preprocessor">&gt;</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="preprocessor">#</span><span class="preprocessor">include</span> <span class="preprocessor">&lt;</span><span class="preprocessor">string</span><span class="preprocessor">&gt;</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="preprocessor">#</span><span class="preprocessor">include</span> <span class="preprocessor">&lt;</span><span class="preprocessor">vector</span><span class="preprocessor">&gt;</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span> </div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="keyword">namespace</span> model_wrapper {</div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span><span class="comment">/**</span></div>
<div class="line"><span class="lineno">   19</span><span class="comment"> * \brief Model wrapper</span></div>
<div class="line"><span class="lineno">   20</span><span class="comment"> */</span></div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="keyword">class</span> <a class="code hl_class" href="classmodel__wrapper_1_1Model.html">Model</a> {</div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="keyword">private</span>:</div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span>  <span class="keyword">const</span> <span class="keywordtype">float</span> m_temperature;</div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span>  <span class="keyword">const</span> std::size_t m_prediction_length;</div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span> </div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span>  llama_model_ptr m_model{<span class="keywordtype">nullptr</span>};</div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span>  <span class="keyword">const</span> llama_vocab *m_vocab;</div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span>  llama_sampler_ptr m_sampler{<span class="keywordtype">nullptr</span>};</div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span> </div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span>  <span class="comment">/**</span></div>
<div class="line"><span class="lineno">   31</span><span class="comment">   * \brief Tokenize the prompt</span></div>
<div class="line"><span class="lineno">   32</span><span class="comment">   * \p</span></div>
<div class="line"><span class="lineno">   33</span><span class="comment">   * \return The tokens</span></div>
<div class="line"><span class="lineno">   34</span><span class="comment">   * \throw std::runtime_error if the prompt cannot be tokenized</span></div>
<div class="line"><span class="lineno">   35</span><span class="comment">   */</span></div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span>  <a class="code hl_function" href="classmodel__wrapper_1_1Model.html#a5a39a265162455ccb5f7872d50e9aeec">std</a>::<a class="code hl_function" href="classmodel__wrapper_1_1Model.html#a5a39a265162455ccb5f7872d50e9aeec">vector</a>&lt;<a class="code hl_function" href="classmodel__wrapper_1_1Model.html#a5a39a265162455ccb5f7872d50e9aeec">llama_token</a>&gt; <a class="code hl_function" href="classmodel__wrapper_1_1Model.html#a5a39a265162455ccb5f7872d50e9aeec">tokenize_prompt</a>(<span class="keyword">const</span> <a class="code hl_function" href="classmodel__wrapper_1_1Model.html#a5a39a265162455ccb5f7872d50e9aeec">std</a>::<a class="code hl_function" href="classmodel__wrapper_1_1Model.html#a5a39a265162455ccb5f7872d50e9aeec">string</a> &amp;<a class="code hl_function" href="classmodel__wrapper_1_1Model.html#a5a39a265162455ccb5f7872d50e9aeec">prompt</a>);</div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span> </div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span>  <span class="comment">/**</span></div>
<div class="line"><span class="lineno">   39</span><span class="comment">   * \brief Initialize the sampler</span></div>
<div class="line"><span class="lineno">   40</span><span class="comment">   */</span></div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classmodel__wrapper_1_1Model.html#ace3515ae4db3331d91ff8fbede50429e">initialize_sampler</a>();</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span> </div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span>  <span class="comment">/**</span></div>
<div class="line"><span class="lineno">   44</span><span class="comment">   * \brief Create the context.</span></div>
<div class="line"><span class="lineno">   45</span><span class="comment">   * \details The context size is determined as</span></div>
<div class="line"><span class="lineno">   46</span><span class="comment">   * number_of_tokens + m_prediction_length.</span></div>
<div class="line"><span class="lineno">   47</span><span class="comment">   * \param number_of_tokens The number of tokens</span></div>
<div class="line"><span class="lineno">   48</span><span class="comment">   * \return The context pointer</span></div>
<div class="line"><span class="lineno">   49</span><span class="comment">   * \throw std::runtime_error if the context cannot be created</span></div>
<div class="line"><span class="lineno">   50</span><span class="comment">   */</span></div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>  <a class="code hl_function" href="classmodel__wrapper_1_1Model.html#aa858451b44fce7c5cb613b4d2b6fd154">llama_context_ptr</a> <a class="code hl_function" href="classmodel__wrapper_1_1Model.html#aa858451b44fce7c5cb613b4d2b6fd154">create_context</a>(<span class="keyword">const</span> <a class="code hl_function" href="classmodel__wrapper_1_1Model.html#aa858451b44fce7c5cb613b4d2b6fd154">std</a>::<a class="code hl_function" href="classmodel__wrapper_1_1Model.html#aa858451b44fce7c5cb613b4d2b6fd154">size_t</a> <a class="code hl_function" href="classmodel__wrapper_1_1Model.html#aa858451b44fce7c5cb613b4d2b6fd154">number_of_tokens</a>);</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span> </div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span><span class="keyword">public</span>:</div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span>  <span class="comment">/**</span></div>
<div class="line"><span class="lineno">   55</span><span class="comment">   * \brief Construct a new Model object</span></div>
<div class="line"><span class="lineno">   56</span><span class="comment">   * \param model_path The path to the model file in GGUF format</span></div>
<div class="line"><span class="lineno">   57</span><span class="comment">   * \param temperature The temperature</span></div>
<div class="line"><span class="lineno">   58</span><span class="comment">   * \param number_of_gpu_layers The number of GPU layers to use</span></div>
<div class="line"><span class="lineno">   59</span><span class="comment">   * \param prediction_length The maximum number of tokens to predict</span></div>
<div class="line"><span class="lineno">   60</span><span class="comment">   * \throw std::runtime_error if the model cannot be loaded</span></div>
<div class="line"><span class="lineno">   61</span><span class="comment">   */</span></div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>  <a class="code hl_function" href="classmodel__wrapper_1_1Model.html#a5fdf892e481f6abc35cf252a46d59f5f">Model</a>(<span class="keyword">const</span> std::string_view model_path, <span class="keyword">const</span> <span class="keywordtype">float</span> temperature,</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span>        <span class="keyword">const</span> int32_t number_of_gpu_layers,</div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>        <span class="keyword">const</span> std::size_t prediction_length);</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span> </div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>  <span class="comment">/**</span></div>
<div class="line"><span class="lineno">   67</span><span class="comment">   * \brief Apply the chat template to the messages</span></div>
<div class="line"><span class="lineno">   68</span><span class="comment">   * \param messages The messages to format</span></div>
<div class="line"><span class="lineno">   69</span><span class="comment">   * \return The formatted prompt</span></div>
<div class="line"><span class="lineno">   70</span><span class="comment">   * \throw std::runtime_error if the chat template cannot be applied</span></div>
<div class="line"><span class="lineno">   71</span><span class="comment">   */</span></div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>  std::string</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span>  <a class="code hl_function" href="classmodel__wrapper_1_1Model.html#abdc90421c561235664f0f88c04668ed4">get_formatted_prompt</a>(<span class="keyword">const</span> std::vector&lt;llama_chat_message&gt; &amp;messages);</div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span> </div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>  <span class="comment">/**</span></div>
<div class="line"><span class="lineno">   76</span><span class="comment">   * \brief Generate a responde from the prompt</span></div>
<div class="line"><span class="lineno">   77</span><span class="comment">   * \details The model generates a response to the prompt by sampling tokens</span></div>
<div class="line"><span class="lineno">   78</span><span class="comment">   * and this function writes to out each token</span></div>
<div class="line"><span class="lineno">   79</span><span class="comment">   * \param prompt The prompt to respond to</span></div>
<div class="line"><span class="lineno">   80</span><span class="comment">   * \param out The output stream to write the response to</span></div>
<div class="line"><span class="lineno">   81</span><span class="comment">   * \throw std::runtime_error if the generation fails</span></div>
<div class="line"><span class="lineno">   82</span><span class="comment">   */</span></div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classmodel__wrapper_1_1Model.html#a2a4705ca07778e0e9e8e052056656c53">generate_response</a>(<span class="keyword">const</span> std::string &amp;prompt, std::ostream &amp;out);</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>};</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span>} <span class="comment">// namespace model_wrapper</span></div>
<div class="ttc" id="aclassmodel__wrapper_1_1Model_html"><div class="ttname"><a href="classmodel__wrapper_1_1Model.html">model_wrapper::Model</a></div><div class="ttdoc">Model wrapper.</div><div class="ttdef"><b>Definition:</b> model.h:21</div></div>
<div class="ttc" id="aclassmodel__wrapper_1_1Model_html_a2a4705ca07778e0e9e8e052056656c53"><div class="ttname"><a href="classmodel__wrapper_1_1Model.html#a2a4705ca07778e0e9e8e052056656c53">model_wrapper::Model::generate_response</a></div><div class="ttdeci">void generate_response(const std::string &amp;prompt, std::ostream &amp;out)</div><div class="ttdoc">Generate a responde from the prompt.</div></div>
<div class="ttc" id="aclassmodel__wrapper_1_1Model_html_a5a39a265162455ccb5f7872d50e9aeec"><div class="ttname"><a href="classmodel__wrapper_1_1Model.html#a5a39a265162455ccb5f7872d50e9aeec">model_wrapper::Model::tokenize_prompt</a></div><div class="ttdeci">std::vector&lt; llama_token &gt; tokenize_prompt(const std::string &amp;prompt)</div><div class="ttdoc">Tokenize the prompt .</div></div>
<div class="ttc" id="aclassmodel__wrapper_1_1Model_html_a5fdf892e481f6abc35cf252a46d59f5f"><div class="ttname"><a href="classmodel__wrapper_1_1Model.html#a5fdf892e481f6abc35cf252a46d59f5f">model_wrapper::Model::Model</a></div><div class="ttdeci">Model(const std::string_view model_path, const float temperature, const int32_t number_of_gpu_layers, const std::size_t prediction_length)</div><div class="ttdoc">Construct a new Model object.</div></div>
<div class="ttc" id="aclassmodel__wrapper_1_1Model_html_aa858451b44fce7c5cb613b4d2b6fd154"><div class="ttname"><a href="classmodel__wrapper_1_1Model.html#aa858451b44fce7c5cb613b4d2b6fd154">model_wrapper::Model::create_context</a></div><div class="ttdeci">llama_context_ptr create_context(const std::size_t number_of_tokens)</div><div class="ttdoc">Create the context.</div></div>
<div class="ttc" id="aclassmodel__wrapper_1_1Model_html_abdc90421c561235664f0f88c04668ed4"><div class="ttname"><a href="classmodel__wrapper_1_1Model.html#abdc90421c561235664f0f88c04668ed4">model_wrapper::Model::get_formatted_prompt</a></div><div class="ttdeci">std::string get_formatted_prompt(const std::vector&lt; llama_chat_message &gt; &amp;messages)</div><div class="ttdoc">Apply the chat template to the messages.</div></div>
<div class="ttc" id="aclassmodel__wrapper_1_1Model_html_ace3515ae4db3331d91ff8fbede50429e"><div class="ttname"><a href="classmodel__wrapper_1_1Model.html#ace3515ae4db3331d91ff8fbede50429e">model_wrapper::Model::initialize_sampler</a></div><div class="ttdeci">void initialize_sampler()</div><div class="ttdoc">Initialize the sampler.</div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><b>model.h</b></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.4 </li>
  </ul>
</div>
</body>
</html>
